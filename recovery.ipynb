{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO List:\n",
    "\n",
    "1) mongo dump / reload on a local machine\n",
    "\n",
    "2) get unique set of ObjectIDs in event.descriptor_id\n",
    "\n",
    "3) get all of the run start/run_stop pairs and their start times\n",
    "\n",
    "4) for each set of events for a given unique ObjectId compute the average time\n",
    "\n",
    "5) sort out which start/stop window the average falls in (might have to pad the start-stops out a bit in time)\n",
    "\n",
    "6) use that association to build new event descriptors\n",
    "\n",
    "7) look at the events in each set and sort out what the data keys are and if you can (easily) extract the shape\n",
    "\n",
    "8) get a list of all of the keys that were used (which will probably be <30) and work with beamline to get mapping back to PVs to reconstruct the source information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MONGO_HOST = 'localhost'\n",
    "MONGO_PORT = 27017\n",
    "MIGRATION_DB = 'datastore2'\n",
    "# 1) mongo dump / reload on a local machine\n",
    "pymongo_client = MongoClient(MONGO_HOST, MONGO_PORT)\n",
    "database = pymongo_client['datastore2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13801\n"
     ]
    }
   ],
   "source": [
    "#2) get unique set of ObjectIDs in event.descriptor_id\n",
    "desc_oids = list()\n",
    "desc_oids = database.event.distinct('descriptor_id')\n",
    "print(len(desc_oids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 3) get all of the run start/run_stop pairs and their start times\n",
    "rstt_crsr = database.run_start.find()\n",
    "pairs = dict()\n",
    "for rstart in rstt_crsr:\n",
    "    try:\n",
    "        run_stop = next(database.run_stop.find({'run_start_id': rstart['_id']}))\n",
    "    except StopIteration:\n",
    "        run_stop = None # there are some rstop that are not created \n",
    "    if run_stop:\n",
    "        time_range = (rstart['time'],run_stop['time'])\n",
    "        pairs[rstart['_id']] = time_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4) for each set of events for a given unique \n",
    "# ObjectId compute the average time\n",
    "def compute_average(descriptor_ids):\n",
    "    descriptors = {}\n",
    "    for entry in descriptor_ids:\n",
    "        ev_crsr = database.event.find({'descriptor_id': entry})\n",
    "        sum, cnt = 0, 0\n",
    "        for ev in ev_crsr:\n",
    "            sum += ev['time']\n",
    "            cnt += 1\n",
    "        avg = sum / cnt\n",
    "        descriptors['id'] = (entry, avg)\n",
    "    return descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 5) sort out which start/stop window the average \n",
    "# falls in (might have to pad the start-stops out a bit in time)\n",
    "rs_desc_pairs = {}\n",
    "for k, v in pairs.items():\n",
    "    # give me all the distinct event descriptors for events in the\n",
    "    # time range between start and stop\n",
    "    # TODO: Figure out what to do for the orphan descriptors\n",
    "    query = {'time': {'$gt': v[0],'$lt': v[1]}}\n",
    "    rs_desc_pairs[k] = database.event.find(query).distinct(key='descriptor_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558366de7368e3b3b857fbf2 {'run_start_id': ObjectId('558368220712a64e78d58c53'), '_id': ObjectId('558366e77368e3b3b857fbf3')}\n",
      "558366de7368e3b3b857fbf2 {'run_start_id': ObjectId('558368220712a64e78d58c53'), '_id': ObjectId('558368250712a64e78d58c54')}\n",
      "558366de7368e3b3b857fbf2 {'run_start_id': ObjectId('558367ea0712a64e78d58c4b'), '_id': ObjectId('558367ed0712a64e78d58c4c')}\n",
      "558366de7368e3b3b857fbf2 {'run_start_id': ObjectId('5583676b0712a64e78d58c43'), '_id': ObjectId('5583676e0712a64e78d58c44')}\n",
      "54e64ce324467976d380b00e {'run_start_id': ObjectId('54e64ce324467976d380afec'), '_id': ObjectId('54e64ce324467976d380b00f')}\n",
      "54e64ce324467976d380b00e {'run_start_id': ObjectId('54e64ce324467976d380afec'), '_id': ObjectId('54e64ce324467976d380afed')}\n",
      "558334e97368e3a5578ab81d {'run_start_id': ObjectId('5583352b0712a63780f7ccdb'), '_id': ObjectId('558334ed7368e3a5578ab81e')}\n",
      "558334e97368e3a5578ab81d {'run_start_id': ObjectId('5583352b0712a63780f7ccdb'), '_id': ObjectId('5583352e0712a63780f7ccdc')}\n"
     ]
    }
   ],
   "source": [
    "# 6) use that association to build new event descriptors\n",
    "from pymongo.errors import OperationFailure\n",
    "for k,v in rs_desc_pairs.items():\n",
    "    for _ in list(v):\n",
    "        try:\n",
    "            database.event_descriptor.insert({'run_start_id':k, '_id':_})\n",
    "        except OperationFailure:\n",
    "            # this is the crap that overlaps\n",
    "            # seems like two consecutive run_starts created right after \n",
    "            print(k, next(database.event_descriptor.find({'_id': _})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sclr_ch1': [100000005.0, 1424213954.194121],\n",
       " 'sclr_ch2': [10097.0, 1424213954.194121],\n",
       " 'sclr_ch3': [7665.0, 1424213954.194121],\n",
       " 'sclr_ch4': [2735.0, 1424213954.194121],\n",
       " 'sclr_ch5': [9645.0, 1424213954.194121],\n",
       " 'sclr_ch6': [3930.0, 1424213954.194121],\n",
       " 'theta': [-1.0000950000000017, 1424214097.306621]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7) look at the events in each set and sort out what the data keys are and if you can (easily) extract the shape\n",
    "\n",
    "from bson import ObjectId\n",
    "\n",
    "database.event.find({\"descriptor_id\" : ObjectId(\"54e3c8537368e3237a36b299\"),}).distinct(key='data')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 8) get a list of all of the keys that were used (which will probably be <30) and work with beamline to get mapping back to \n",
    "# PVs to reconstruct the source information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
