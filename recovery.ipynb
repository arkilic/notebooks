{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Strategy:_\n",
    "\n",
    "1. mongo dump / reload on a local machine\n",
    "\n",
    "2. Compose ranges where start is run_start time and stop is run_stop time\n",
    "\n",
    "3. Compose a dictionary keyed on run_start oid that holds run_start and run_stop tuples\n",
    "\n",
    "4. iterate over the range dictionary and get distinct event_descriptor_ids for events that fall under each range and put these descriptors in a dictionary formatted as rs_desc_pairs['run_start_id'] = distinct_event_descriptors\n",
    "\n",
    "5. By iterating over the dict's contents in step 4, findthe cases that an event_descriptor is associated with more than one run_start (there are 8 and this is due to creation of two consecutive run_starts not too far apart in time). Pick the run_start that is closest to the event_descriptor in time. This step results in desc_rstart_pairs dict where each event_descriptor has a corresponding run_start\n",
    "\n",
    "6. For event_descriptors that I have in desc_rstart_pairs, get distinct data fields. This information will be stored in dt_key dict where keys are event_descriptor oids and contents are the corresponding data keys and their shapes \n",
    "\n",
    "7. Extract the source of all keys from the beamline. Get all keys from the beamline \n",
    "\n",
    "8. Using steps 5, 6, and 7 create and insert all event_descriptors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from bson import ObjectId\n",
    "from pymongo.errors import OperationFailure\n",
    "from collections import deque\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MONGO_HOST = 'localhost'\n",
    "MONGO_PORT = 27017\n",
    "MIGRATION_DB = 'datastore2'\n",
    "# 1) mongo dump / reload on a local machine\n",
    "pymongo_client = MongoClient(MONGO_HOST, MONGO_PORT)\n",
    "database = pymongo_client['datastore2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13801\n"
     ]
    }
   ],
   "source": [
    "desc_oids = list()\n",
    "desc_oids = database.event.distinct('descriptor_id')\n",
    "print(len(desc_oids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2. Compose ranges where start is run_start time and stop is run_stop time\n",
    "\n",
    "# 3. Compose a dictionary keyed on run_start oid that holds run_start and run_stop tuples\n",
    "\n",
    "rstt_crsr = database.run_start.find()\n",
    "pairs = dict()\n",
    "for rstart in rstt_crsr:\n",
    "    try:\n",
    "        run_stop = next(database.run_stop.find({'run_start_id': rstart['_id']}))\n",
    "    except StopIteration:\n",
    "        run_stop = None \n",
    "    # there are some rstop that are not created. What to do with these!? Igonore for now\n",
    "    if run_stop:\n",
    "        time_range = (rstart['time'], run_stop['time'])\n",
    "        pairs[rstart['_id']] = time_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4. iterate over the range dictionary and get distinct event_descriptor_ids for events that fall under each range and put these descriptors in a dictionary formatted as rs_desc_pairs['run_start_id'] = distinct_event_descriptors\n",
    "\n",
    "rs_desc_pairs = {}\n",
    "for k, v in pairs.items():\n",
    "    # give me all the distinct event descriptors for events in the\n",
    "    # time range between start and stop\n",
    "    query = {'time': {'$gt': v[0],'$lt': v[1]}}\n",
    "    rs_desc_pairs[k] = database.event.find(query).distinct(key='descriptor_id')\n",
    "    # rs_desc_pairs holds run_start event_descriptor pairs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-06-18 21:16:27+00:00 2015-06-18 21:15:25+00:00 2015-06-18 21:15:21+00:00\n",
      "5583352b0712a63780f7ccdb 558334ed7368e3a5578ab81e 558334e97368e3a5578ab81d\n",
      "558334e97368e3a5578ab81d 558334ed7368e3a5578ab81e\n",
      "2015-06-18 21:16:27+00:00 2015-06-18 21:16:30+00:00 2015-06-18 21:15:21+00:00\n",
      "5583352b0712a63780f7ccdb 5583352e0712a63780f7ccdc 558334e97368e3a5578ab81d\n",
      "5583352b0712a63780f7ccdb 5583352e0712a63780f7ccdc\n",
      "2015-02-19 20:51:47+00:00 2015-02-19 20:51:47+00:00 2015-02-19 20:51:47+00:00\n",
      "54e64ce324467976d380b00e 54e64ce324467976d380afed 54e64ce324467976d380afec\n",
      "54e64ce324467976d380afec 54e64ce324467976d380afed\n",
      "2015-02-19 20:51:47+00:00 2015-02-19 20:51:47+00:00 2015-02-19 20:51:47+00:00\n",
      "54e64ce324467976d380b00e 54e64ce324467976d380b00f 54e64ce324467976d380afec\n",
      "54e64ce324467976d380b00e 54e64ce324467976d380b00f\n",
      "2015-06-19 00:53:54+00:00 2015-06-19 00:48:39+00:00 2015-06-19 00:48:30+00:00\n",
      "558368220712a64e78d58c53 558366e77368e3b3b857fbf3 558366de7368e3b3b857fbf2\n",
      "558366de7368e3b3b857fbf2 558366e77368e3b3b857fbf3\n",
      "2015-06-19 00:53:54+00:00 2015-06-19 00:53:57+00:00 2015-06-19 00:48:30+00:00\n",
      "558368220712a64e78d58c53 558368250712a64e78d58c54 558366de7368e3b3b857fbf2\n",
      "558368220712a64e78d58c53 558368250712a64e78d58c54\n",
      "2015-06-19 00:52:58+00:00 2015-06-19 00:53:01+00:00 2015-06-19 00:48:30+00:00\n",
      "558367ea0712a64e78d58c4b 558367ed0712a64e78d58c4c 558366de7368e3b3b857fbf2\n",
      "558367ea0712a64e78d58c4b 558367ed0712a64e78d58c4c\n",
      "2015-06-19 00:48:30+00:00 2015-06-19 00:50:54+00:00 2015-06-19 00:50:51+00:00\n",
      "558366de7368e3b3b857fbf2 5583676e0712a64e78d58c44 5583676b0712a64e78d58c43\n",
      "5583676b0712a64e78d58c43 5583676e0712a64e78d58c44\n"
     ]
    }
   ],
   "source": [
    "# 5. By iterating over the dict's contents in step 4, find \n",
    "# the cases that an event_descriptor is associated with more than \n",
    "# one run_start (there are 8 and this is due to creation of two consecutive \n",
    "# run_starts not too far apart in time). Pick the run_start that is closest \n",
    "# to the event_descriptor in time. This step results in desc_rstart_pairs dict where each event_descriptor has a corresponding run_start\n",
    "\n",
    "\n",
    "descs = deque()\n",
    "desc_rstart_pairs = {}\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, str(a), str(b)).ratio()\n",
    "\n",
    "for k,v in rs_desc_pairs.items():\n",
    "    for _ in list(v):\n",
    "        # TODO: Add the decision making process for those descriptors that are duplicated\n",
    "        if _ not in descs:\n",
    "            descs.append(_)\n",
    "            desc_rstart_pairs[_] = k\n",
    "        else:\n",
    "            # For the 8 overlapping descriptors, select the most likely\n",
    "            # run_start (oid is +1 is as close as it can possibly get)\n",
    "            print(desc_rstart_pairs[_].generation_time, _.generation_time, k.generation_time)\n",
    "            print(desc_rstart_pairs[_], _, k)\n",
    "            if similar(desc_rstart_pairs[_], _) < similar(k, _):\n",
    "                desc_rstart_pairs[_] = k\n",
    "            print(desc_rstart_pairs[_], _)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56545ba37368e3ce421164b9\n",
      "565135f07368e3ce42a6df0b\n",
      "565232d97368e3ce42cef358\n",
      "564eed4a7368e3774099aeaa\n",
      "5652e9cc7368e3ce42e54249\n",
      "56518b2f7368e3ce42b4d475\n",
      "56537d787368e3ce42fe1913\n",
      "5651e75c7368e3ce42c563f6\n",
      "5651b7867368e3ce42bd1c16\n",
      "56534c197368e3ce42f5d18a\n",
      "56531fc17368e3ce42ed89e5\n",
      "564f4eaf7368e37740aa5712\n",
      "564f19857368e37740a202dd\n",
      "5654247f7368e3ce42091d20\n"
     ]
    }
   ],
   "source": [
    "# 6. For event_descriptors that I have in desc_rstart_pairs, get distinct data fields. \n",
    "# This information will be stored in dt_key dict where keys are event_descriptor oids and contents are the corresponding data keys and their shapes \n",
    "\n",
    "\n",
    "dt_key = {}\n",
    "\n",
    "# TODO: Compose data keys\n",
    "# Get all data keys and corresponding shapes\n",
    "# Get source info\n",
    "# Tada!\n",
    "for d in descs:\n",
    "    try:\n",
    "        res = database.event.find({\"descriptor_id\" : ObjectId(d)}).distinct(key='data')[0]\n",
    "    except OperationFailure:\n",
    "        print(d)\n",
    "    dt_key[d] = res.keys()\n",
    "# the difference in the number of different descriptor count is\n",
    "# due to run_stop-less run_starts\n",
    "\n",
    "\n",
    "# There is a 16 MB limit on distinct. SOmetimes, even the smallest documents \n",
    "# get caught in the threshold and get neglected. Need to fix these "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunStart time 1424357816.968672\n",
      "Event time  1424357850.284224\n",
      "Event time  1424357883.543736\n",
      "Event time  1424357913.724856\n",
      "Event time  1424357946.947482\n",
      "Event time  1424357973.540224\n",
      "Event time  1424358006.766089\n",
      "Event time  1424358033.844119\n",
      "Event time  1424358067.188064\n",
      "Event time  1424358093.697332\n",
      "Event time  1424358126.950872\n",
      "Event time  1424358153.969373\n",
      "RunStop time 1424358154.394573\n"
     ]
    }
   ],
   "source": [
    "# sanity check. Make sure events are between stop and start\n",
    "t = ObjectId('54e5f9b87368e36ad949a25b')\n",
    "print('RunStart time', next(database.run_start.find({'_id': t}))['time'])\n",
    "crsr = database.event.find({'descriptor_id': rs_desc_pairs[t][0]})\n",
    "for c in crsr:\n",
    "    print('Event time ',c['time'])\n",
    "print('RunStop time', next(database.run_stop.find({'run_start_id': t}))['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 7. Extract the source of all keys from the beamline. Get all keys from the beamline \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 8. Using steps 5, 6, and 7 create and insert all event_descriptors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
