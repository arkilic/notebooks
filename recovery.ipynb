{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Strategy:_\n",
    "\n",
    "1. mongo dump / reload on a local machine\n",
    "\n",
    "2. Compose ranges where start is run_start time and stop is run_stop time\n",
    "\n",
    "3. Compose a dictionary keyed on run_start oid that holds run_start and run_stop tuples\n",
    "\n",
    "4. iterate over the range dictionary and get distinct event_descriptor_ids for events that fall under each range and put these descriptors in a dictionary formatted as rs_desc_pairs['run_start_id'] = distinct_event_descriptors\n",
    "\n",
    "5. By iterating over the dict's contents in step 4, findthe cases that an event_descriptor is associated with more than one run_start (there are 8 and this is due to creation of two consecutive run_starts not too far apart in time). Pick the run_start that is closest to the event_descriptor in time. This step results in desc_rstart_pairs dict where each event_descriptor has a corresponding run_start\n",
    "\n",
    "6. For event_descriptors that I have in desc_rstart_pairs, get distinct data fields. This information will be stored in dt_key dict where keys are event_descriptor oids and contents are the corresponding data keys and their shapes \n",
    "\n",
    "7. Extract the source of all keys from the beamline. Get all keys from the beamline \n",
    "\n",
    "8. Using steps 5, 6, and 7 create and insert all event_descriptors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from bson import ObjectId\n",
    "from pymongo.errors import OperationFailure\n",
    "from collections import deque\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MONGO_HOST = 'localhost'\n",
    "MONGO_PORT = 27017\n",
    "MIGRATION_DB = 'datastore2'\n",
    "# 1) mongo dump / reload on a local machine\n",
    "pymongo_client = MongoClient(MONGO_HOST, MONGO_PORT)\n",
    "database = pymongo_client['datastore2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13801\n"
     ]
    }
   ],
   "source": [
    "desc_oids = list()\n",
    "desc_oids = database.event.distinct('descriptor_id')\n",
    "print(len(desc_oids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2. Compose ranges where start is run_start time and stop is run_stop time\n",
    "\n",
    "# 3. Compose a dictionary keyed on run_start oid that holds run_start and run_stop tuples\n",
    "\n",
    "rstt_crsr = database.run_start.find()\n",
    "pairs = dict()\n",
    "for rstart in rstt_crsr:\n",
    "    try:\n",
    "        run_stop = next(database.run_stop.find({'run_start_id': rstart['_id']}))\n",
    "    except StopIteration:\n",
    "        run_stop = None \n",
    "    # there are some rstop that are not created. What to do with these!? Igonore for now\n",
    "    if run_stop:\n",
    "        time_range = (rstart['time'], run_stop['time'])\n",
    "        pairs[rstart['_id']] = time_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4. iterate over the range dictionary and get distinct event_descriptor_ids for events that fall under each range and put these descriptors in a dictionary formatted as rs_desc_pairs['run_start_id'] = distinct_event_descriptors\n",
    "\n",
    "rs_desc_pairs = {}\n",
    "for k, v in pairs.items():\n",
    "    # give me all the distinct event descriptors for events in the\n",
    "    # time range between start and stop\n",
    "    query = {'time': {'$gt': v[0],'$lt': v[1]}}\n",
    "    rs_desc_pairs[k] = database.event.find(query).distinct(key='descriptor_id')\n",
    "    # rs_desc_pairs holds run_start event_descriptor pairs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_start 1 2015-06-19 00:48:30+00:00 run_start 2 2015-06-19 00:52:58+00:00 descriptor 2015-06-19 00:53:01+00:00\n",
      "run_start 1 2015-06-19 00:48:30+00:00 run_start 2 2015-06-19 00:50:51+00:00 descriptor 2015-06-19 00:50:54+00:00\n",
      "run_start 1 2015-02-19 20:51:47+00:00 run_start 2 2015-02-19 20:51:47+00:00 descriptor 2015-02-19 20:51:47+00:00\n",
      "run_start 1 2015-02-19 20:51:47+00:00 run_start 2 2015-02-19 20:51:47+00:00 descriptor 2015-02-19 20:51:47+00:00\n",
      "run_start 1 2015-06-19 00:48:30+00:00 run_start 2 2015-06-19 00:53:54+00:00 descriptor 2015-06-19 00:53:57+00:00\n",
      "run_start 1 2015-06-19 00:48:30+00:00 run_start 2 2015-06-19 00:53:54+00:00 descriptor 2015-06-19 00:48:39+00:00\n",
      "run_start 1 2015-06-18 21:15:21+00:00 run_start 2 2015-06-18 21:16:27+00:00 descriptor 2015-06-18 21:15:25+00:00\n",
      "run_start 1 2015-06-18 21:15:21+00:00 run_start 2 2015-06-18 21:16:27+00:00 descriptor 2015-06-18 21:16:30+00:00\n"
     ]
    }
   ],
   "source": [
    "# 5. By iterating over the dict's contents in step 4, find \n",
    "# the cases that an event_descriptor is associated with more than \n",
    "# one run_start (there are 8 and this is due to creation of two consecutive \n",
    "# run_starts not too far apart in time). Pick the run_start that is closest \n",
    "# to the event_descriptor in time. This step results in desc_rstart_pairs dict where each event_descriptor has a corresponding run_start\n",
    "\n",
    "\n",
    "descs = deque()\n",
    "desc_rstart_pairs = {}\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, str(a), str(b)).ratio()\n",
    "# One run_start can have multiple descriptors. rs_desc_pairs holds run_start (k) and its\n",
    "# corresponding descriptors (v)\n",
    "for k,v in rs_desc_pairs.items():\n",
    "    for _ in list(v):\n",
    "        # Check if this descriptor has already been seen\n",
    "        # if so, compare the two run_starts and pick the one closest\n",
    "        # to the descriptor in time\n",
    "        if _ not in descs:\n",
    "            descs.append(_)\n",
    "            desc_rstart_pairs[_] = k\n",
    "        else:\n",
    "            # For the 8 overlapping descriptors, select the most likely\n",
    "            # run_start (oid is +1 is as close as it can possibly get)\n",
    "            print('run_start 1', desc_rstart_pairs[_].generation_time,\n",
    "                  'run_start 2', k.generation_time,\n",
    "                  'descriptor', _.generation_time)    \n",
    "            if similar(desc_rstart_pairs[_], _) < similar(k, _):\n",
    "                desc_rstart_pairs[_] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 6. For event_descriptors that I have in desc_rstart_pairs, get distinct data fields. \n",
    "# This information will be stored in dt_key dict where keys are event_descriptor oids and contents are the corresponding data keys and their shapes \n",
    "data_key_templates = {}\n",
    "leftovers = []\n",
    "unique_keys = []\n",
    "for d in descs:\n",
    "    dt_key = {}\n",
    "    try:\n",
    "        res = database.event.find({\"descriptor_id\" : ObjectId(d)}).distinct(key='data')[0]\n",
    "    except OperationFailure:\n",
    "        leftovers.append(d)\n",
    "    for k, v in res.items():\n",
    "        if k not in unique_keys:\n",
    "            unique_keys.append(k)\n",
    "        if (type(v[0])==int) or (type(v[0])==float):\n",
    "            data_type = 'number'\n",
    "        elif (type(v[0])==str):\n",
    "            data_type = 'array'\n",
    "        else:\n",
    "            data_type = type(v[0])\n",
    "        try:\n",
    "            if (1356998400.0 <= v[1] <= 1452612569587.0): #2013 to now\n",
    "                shape = []\n",
    "            else:\n",
    "                shape = (len(v),)\n",
    "        except TypeError:\n",
    "            shape = []\n",
    "        if data_type == 'array':\n",
    "            dt_key[k] = {'shape': shape, 'dtype': data_type, \n",
    "                         'external': 'FILESTORE:'}\n",
    "        else:\n",
    "            dt_key[k] = {'shape': shape, 'dtype': data_type}\n",
    "    data_key_templates[d] = dt_key\n",
    "\n",
    "# the difference in the number of different descriptor count is\n",
    "# due to run_stop-less run_starts\n",
    "# There is a 16 MB limit on distinct. SOmetimes, even the smallest documents \n",
    "# get caught in the threshold and get neglected. Catch those that are excluded and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223  unique keys\n"
     ]
    }
   ],
   "source": [
    "print(len(unique_keys), ' unique keys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[71457568.0, 816875253.5713149]\n",
      "564f4eaf7368e37740aa5712 {'diag6_flyer1': {'dtype': 'number', 'shape': (2,)}}\n",
      "[161576467.0, 817206249.6746507]\n",
      "56545ba37368e3ce421164b9 {'diag6_flyer1': {'dtype': 'number', 'shape': (2,)}}\n",
      "[161861225.0, 817064735.4397624]\n",
      "565232d97368e3ce42cef358 {'diag6_flyer1': {'dtype': 'number', 'shape': (2,)}}\n",
      "[163193577.0, 817111571.0875765]\n",
      "5652e9cc7368e3ce42e54249 {'diag6_flyer1': {'dtype': 'number', 'shape': (2,)}}\n",
      "[164138955.0, 817192133.8452698]\n",
      "5654247f7368e3ce42091d20 {'diag6_flyer1': {'dtype': 'number', 'shape': (2,)}}\n",
      "[162215895.0, 816999978.2690133]\n",
      "565135f07368e3ce42a6df0b {'diag6_flyer1': {'dtype': 'number', 'shape': (2,)}}\n",
      "[160588260.0, 817149374.8139615]\n",
      "56537d787368e3ce42fe1913 {'diag6_flyer1': {'dtype': 'number', 'shape': (2,)}}\n",
      "[160462186.0, 817136734.4582783]\n",
      "56534c197368e3ce42f5d18a {'diag6_flyer1': {'dtype': 'number', 'shape': (2,)}}\n",
      "[162076572.0, 817125383.6342568]\n",
      "56531fc17368e3ce42ed89e5 {'diag6_flyer1': {'dtype': 'number', 'shape': (2,)}}\n",
      "[160310271.0, 817021813.2079449]\n",
      "56518b2f7368e3ce42b4d475 {'diag6_flyer1': {'dtype': 'number', 'shape': (2,)}}\n",
      "[157983299.0, 817033163.191671]\n",
      "5651b7867368e3ce42bd1c16 {'diag6_flyer1': {'dtype': 'number', 'shape': (2,)}}\n",
      "[374074634.0, 816861644.4276351]\n",
      "564f19857368e37740a202dd {'diag6_flyer1': {'dtype': 'number', 'shape': (2,)}}\n",
      "[69614083.0, 816850321.1048607]\n",
      "564eed4a7368e3774099aeaa {'diag6_flyer1': {'dtype': 'number', 'shape': (2,)}}\n",
      "[163148111.0, 817045410.323622]\n",
      "5651e75c7368e3ce42c563f6 {'diag6_flyer1': {'dtype': 'number', 'shape': (2,)}}\n"
     ]
    }
   ],
   "source": [
    "# Add the leftovers to the dict\n",
    "m_templates = {}\n",
    "for l in leftovers:\n",
    "    dt_key = {}\n",
    "    res = database.event.find({\"descriptor_id\" : ObjectId(l)})\n",
    "    data = next(res)['data']\n",
    "    for k, v in data.items():\n",
    "        print(v)\n",
    "        if k not in unique_keys:\n",
    "            unique_keys.append(k)\n",
    "        if (type(v[0])==int) or (type(v[0])==float):\n",
    "            data_type = 'number'\n",
    "        elif (type(v[0])==str):\n",
    "            data_type = 'array'\n",
    "        else:\n",
    "            data_type = type(v[0])\n",
    "        try:\n",
    "            if (1356998400.0 <= v[1] <= 1452612569587.0): #2013 to now\n",
    "                shape = []\n",
    "            else:\n",
    "                shape = (len(v),)\n",
    "        except TypeError:\n",
    "            shape = []\n",
    "        if data_type == 'array':\n",
    "            dt_key[k] = {'shape': shape, 'dtype': data_type, \n",
    "                         'external': 'FILESTORE:'}\n",
    "        else:\n",
    "            dt_key[k] = {'shape': shape, 'dtype': data_type}\n",
    "        data_key_templates[l] = dt_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunStart time 1424357816.968672\n",
      "54e5f9da7368e36ad949a25c\n",
      "Event time  1424357850.284224 54e5f9da7368e36ad949a25d\n",
      "Event time  1424357883.543736 54e5f9fb7368e36ad949a25e\n",
      "Event time  1424357913.724856 54e5fa197368e36ad949a25f\n",
      "Event time  1424357946.947482 54e5fa3a7368e36ad949a260\n",
      "Event time  1424357973.540224 54e5fa557368e36ad949a261\n",
      "Event time  1424358006.766089 54e5fa767368e36ad949a262\n",
      "Event time  1424358033.844119 54e5fa917368e36ad949a263\n",
      "Event time  1424358067.188064 54e5fab37368e36ad949a264\n",
      "Event time  1424358093.697332 54e5facd7368e36ad949a265\n",
      "Event time  1424358126.950872 54e5faee7368e36ad949a266\n",
      "Event time  1424358153.969373 54e5fb0a7368e36ad949a267\n",
      "RunStop time 1424358154.394573\n"
     ]
    }
   ],
   "source": [
    "# sanity check. Make sure events are between stop and start for \"some\" ObjectId\n",
    "t = ObjectId('54e5f9b87368e36ad949a25b')\n",
    "print('RunStart time', next(database.run_start.find({'_id': t}))['time'])\n",
    "print(rs_desc_pairs[t][0])\n",
    "crsr = database.event.find({'descriptor_id': rs_desc_pairs[t][0]})\n",
    "for c in crsr:\n",
    "    print('Event time ',c['time'], c['_id'])\n",
    "print('RunStop time', next(database.run_stop.find({'run_start_id': t}))['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 7. Extract the source of all keys from the beamline. Get all keys from the beamline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 8. Using steps 5, 6, and 7 create and insert all event_descriptors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'diag6_flyer1': {'dtype': 'number', 'shape': (2,)}}\n"
     ]
    }
   ],
   "source": [
    "a = [str(key).split(', ') for key in data_key_templates.keys()]\n",
    "\n",
    "print(data_key_templates[ObjectId(a[1199][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dtype': 'array', 'external': 'FILESTORE:', 'shape': []}\n"
     ]
    }
   ],
   "source": [
    "print(data_key_templates[ObjectId(a[199][0])]['fccd_image_lightfield'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(a[1199][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
